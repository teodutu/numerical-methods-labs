{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Methods Team                                                                                        \n",
    "     _Andreea-Diana Oltean_ <br>\n",
    "     _Carmen Popa_ <br>\n",
    "     _Ruxandra-Georgiana Rusu_ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metode Iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiție și clasificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative sunt tehnici care obțin soluțiile unui sistem liniar prin aproximări succesive la fiecare pas. Acestea sunt de două feluri, staționare și nestaționare. \n",
    "\n",
    "Cele **staționare** sunt metode mai vechi apărute, ușor de înțeles și de implementat. Acestea presupun ca la fiecare pas să se execute aceleași operații pe vectorul curent care reține soluția. În acest laborator vom discuta despre **Jacobi**, **Gauss-Seidel** și **Suprarelaxare** în cadrul metodelor iterative staționare.\n",
    "\n",
    "Metodele __nestaționare__ sunt mai nou apărute, mai greu de implementat, dar mai eficiente. Nu vor fi acoperite în acest laborator, dar ca exemplu am putea menționa **Metoda Gradientului Conjugat**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum funcționează?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodele iterative se bazează pe aproximări succesive. Să presupunem că avem de rezolvat sistemul $Ax = b$. Începem rezolvarea cu o aproximare inițială $x = x_0$, pentru oricare $x_0$. La pasul curent ($i$), calculăm o nouă aproximare, bazată pe cea de la pasul anterior ($i - 1$). Astfel, se obține un șir de aproximări $x_0, x_1, x_2, ..., x_k, ...$. Cu cât permitem mai multe iterații, cu atât solutia este mai apropiată de cea exactă. Cu alte cuvinte, cu cât indicele lui x este mai mare, cu atât se apropie mai mult de adevărata soluție a ecuației $Ax = b$. Deci, când $k \\rightarrow \\infty$, șirul de soluții converge la soluția $x = A^{-1}b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forma matriceală a soluției este:\n",
    "$$x^{k + 1} = G \\cdot x^k + c, k \\in \\{0, 1, 2 \\dots\\}$$\n",
    "unde $x^{k}$ și $x^{k + 1}$ repezintă aproximările la pașii $k$ si $k + 1$, <br>\n",
    "$G$ este matricea de iterație, iar $c$ este un vector coloană ce vor fi explicate mai jos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum știu că am găsit soluția?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În cadrul metodelor iterative nu căutăm soluția exactă, ci căutăm o aprximare cât mai bună a acesteia. Cu cât parcurgem mai multe iterații, cu atât obținem o aproximare mai bună, însă cum știm că ne putem opri din căutare? \n",
    "\n",
    "Ne oprim când o soluție nu diferă foarte mult de cea precedentă, însemnând că algoritmul converge și valorile nu se vor mai schimba mult din acest moment. Noi stabilim când se întâmplă asta, alegând o toleranță destul de mică, de exemplu 0.001 sau 0.0001. Formula după care ne ghidăm este: \n",
    "$|x^{k + 1} - x^{k}| < tol$\n",
    "\n",
    "#### Observație: \n",
    "Numărul de zerouri dupa virgulă în valoarea lui epsilon oferă precizie. $\\varepsilon$ = 0.001 oferă o precizie de două zecimale exacte, pe cand 0.0001 oferă trei zecimale exacte.\n",
    "\n",
    "O altă condiție de oprire ar putea fi atingerea numărului maxim de iterații, chiar dacă nu am găsit o aproximare suficient de bună pentru sistemul dat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prea multă teorie, ce se face mai concret? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pornind de la sistemul $Ax = b$, scriem matricea $A$ ca diferență de două matrice, $A = N - P$.\n",
    "Sistemul este prelucrat astfel:\n",
    "$$(N - P)x = b$$\n",
    "$$Nx - Px = b$$\n",
    "$$Nx = Px + b$$\n",
    "$$x = N^{-1}Px + N^{-1}b$$\n",
    "$$x = Gx + c$$\n",
    "\n",
    "$G$ este matricea de iterație de care vorbeam mai devreme, care aparține lui $R^{nxn}$, iar $c$ este un vector coloană din $R^n$.\n",
    "\n",
    "#### Condiție de convergență:\n",
    "${\\rho(G)} < 1$, unde ${\\rho(G)} = max|{\\lambda}_{i}|$, numită raza spectrală, $\\forall \\lambda_i \\in G$, unde $\\lambda_i$ sunt valorile proprii ale matricei $G$.\n",
    "\n",
    "Pentru **Gauss-Seidel**, putem arăta convergența și dacă demonstrăm că matricea $G$ este diagonal dominantă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matricile $N$ și $P$ sunt calculate, de la o metodă la alta, în funcție de matricea $D$ (diagonala lui $A$), $L$ (matricea formată din elementele de sub diagonala principală a lui $A$) și $U$ (matricea formată din elementele de deasupra diagonalei principale a lui A). \n",
    "\n",
    "#### Exemplu:\n",
    "Fie matricea $A = \n",
    "\\begin{bmatrix}\n",
    "    1 & 5 & -3 \\\\\n",
    "    6 & 10 & 2 \\\\\n",
    "    -1 & 7 & 8 \\\\ \n",
    "    \\end{bmatrix}$ <br>.\n",
    "\n",
    "Atunci, $D =\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 \\\\\n",
    "    0 & 10 & 0 \\\\\n",
    "    0 & 0 & 8 \\\\ \n",
    "    \\end{bmatrix}$\n",
    ", $L =\n",
    "\\begin{bmatrix}\n",
    "    0 & 0 & 0 \\\\\n",
    "    6 & 0 & 0 \\\\\n",
    "    -1 & 7 & 0 \\\\ \n",
    "    \\end{bmatrix}$\n",
    "și $U =\n",
    "\\begin{bmatrix}\n",
    "    0 & 5 & -3 \\\\\n",
    "    0 & 0 & 2 \\\\\n",
    "    0 & 0 & 0 \\\\ \n",
    "    \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [D, L, U] = DivideMatrix(A)\n",
    "    % Completați următoarele linii pentru a calcula D, L, U\n",
    "    % Hint: funcțiile diag, tril, triu\n",
    "    D = NaN;\n",
    "    L = NaN;\n",
    "    U = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[D, L, U] = DivideMatrix([1 5 -3; 6 10 2; -1 7 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[passed, total] = test (\"DivideMatrix.test\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jacobi** este o metodă iterativă, folosită pentru calculul sistemelor liniare de mici dimensiuni, întrucât timpul necesar pentru a atinge acuratețea dorită este considerabil mai mic, față de cel al metodelor directe (Eliminarea Gaussiana). Aceasta este o metodă eficientă, atât spațial, cât și temporal, pentru calculul matricilor de dimensiuni mari care au multe intrări 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formule Jacobi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pornind de la $Ax = b$ și $A = N - P$, alegem $N = D$ și $P = L + U$. Astfel, $G = N - P = D^{-1}(L + U)$.\n",
    "\n",
    "Soluția recurentă a sistemului este:\n",
    "$$x_i^{(p + 1)} = \\displaystyle\\frac{b_i - \\sum_{j = 1, j \\neq i}^{n} a_{ij}x_j^{(p)}}{a_{ii}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergenta metodei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condiția necesară și suficientă pentru ca o matrice A să fie convergentă este ca $\\rho(G)$ < 1, unde $\\rho(G)$ este raza spectrală, adică max|$\\lambda_i$| < 1 $\\forall$ $\\lambda_i$ $\\in$ G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [success] = ConvergesJacobi(A)\n",
    "    % Completați următoarele linii pentru a stabili daca matricea A converge pentru metoda Jacobi\n",
    "    N = NaN;\n",
    "    P = NaN;\n",
    "    G = NaN;\n",
    "    % Calculați raza spectrală a matricei G\n",
    "    spectral_radius = NaN;\n",
    "    success = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[success] = ConvergesJacobi([1 5 -3; 6 10 2; -1 7 8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[passed, total] = test (\"ConvergesJacobi.test\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [x_current_step step] = Jacobi(A, b, x0, tol, max_iter)\n",
    "    % TODO 1: Verificați dacă metoda Jacobi converge pentru matricea A și în caz contrar returnați [NaN, -1]\n",
    "    success = NaN;\n",
    "    \n",
    "    n = length(b);\n",
    "    x_last_step = x0;\n",
    "    x_current_step = x0;\n",
    "    % Iterează până la numărul maxim de pași acceptat\n",
    "    for step = 1 : max_iter\n",
    "        % Pentru fiecare element din vectorul soluție\n",
    "        for i = 1 : n\n",
    "            % TODO 2: Calculează suma termenilor\n",
    "            current_step_sum = NaN;\n",
    "\n",
    "            % TODO 3: Calculează noua valoare a elementului x(i)\n",
    "        endfor\n",
    "\n",
    "        % TODO 4: Verifică daca s-a ajuns la o soluție suficient de bună\n",
    "        % Hint: funcția norm\n",
    "        \n",
    "        % TODO 5: Actualizează soluția precedentă cu cea curentă\n",
    "        x_last_step = x_current_step;\n",
    "    endfor\n",
    "endfunction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gauss-Seidel** este o metodă iterativă similară cu **Jacobi**, discutată anterior. Diferența între ele este că **Jacobi** calculează soluția de la pasul $i + 1$ bazându-se în totalitate pe soluția de la pasul $i$, pe când **Gauss-Seidel** se bazează pe soluțiia de la pasul $i$, dar și de soluția parțial calculată de la pasul $i + 1$.\n",
    "\n",
    "Mai clar, să zicem ca $x_0 = (a_0, b_0, c_0)$ este soluția inițială și $x_1 = (a_1, b_1, c_1)$ soluția următoare.\n",
    "La pasul 1, Jacobi ar calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$. De asemenea, ar calcula și $b_1$ și $c_1$ tot în funcție de $a_0$, $b_0$ și $c_0$.\n",
    "Gauss-Seidel începe prin a calcula $a_1$ în funcție de $a_0$, $b_0$ și $c_0$, deoarece nu a calculat încă alte valori la pasul curent. Însă pentru a-l calcula pe $b_1$ folosește, în loc de $a_0$, valoarea lui $a_1$ calculată pentru soluția de la pasul curent. Astfel, $b_1$ e calculat folosind $a_1$, $b_0$ și $c_0$, iar $c_1$ e calculat folosind $a_1$, $b_1$ și $c_0$.\n",
    "\n",
    "#### Observație\n",
    "Gauss-Seidel converge mai repede decât Jacobi, adică găsește o soluție suficient de bună, care să satisfacă relația cu  $\\varepsilon$, în mai puțini pași."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulele de la Gauss-Seidel\n",
    "\n",
    "Pornind de la $Ax = b$ și $A = N - P$, alegem $N = D - L$ și $P = U$. <br> Astfel, $G = N - P = (D - L)^{-1}U$.\n",
    "\n",
    "Soluția recurentă a sistemului este: <br>\n",
    "$$x_i^{p + 1} = \\frac{b_i - \\sum_{j = 1}^{i - 1} a_{ij}x_j^{p + 1} - \\sum_{j = i + 1}^{n} a_{ij}x_j^{p}}{a_{ii}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [success] = ConvergesGaussSeidel(A)\n",
    "    % Completați următoarele linii pentru a stabili daca matricea A converge pentru metoda Gauss-Seidel\n",
    "    % Hint: Folosiți funcția DivideMatrix\n",
    "    N = NaN;\n",
    "    P = NaN;\n",
    "    G = NaN;\n",
    "    % Calculați raza spectrală a matricei G\n",
    "    spectral_radius = NaN;\n",
    "    success = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[success] = ConvergesGaussSeidel([1 5 -3; 6 10 2; -1 7 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[passed, total] = test (\"ConvergesGaussSeidel.test\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [x_current_step step] = GaussSeidel(A, b, x0, tol, max_iter)\n",
    "    % TODO 1: Verificați dacă metoda Gauss-Seidel converge pentru matricea A și în caz contrar returnați [NaN, -1]\n",
    "    success = NaN;\n",
    "    \n",
    "    n = length(b);\n",
    "    x_last_step = x0;\n",
    "    x_current_step = x0;\n",
    "    % Iterează până la numărul maxim de pași acceptat\n",
    "    for step = 1 : max_iter\n",
    "        % Pentru fiecare element din vectorul soluție\n",
    "        for i = 1 : n\n",
    "            % TODO 2: Calculează suma care folosește valori calculate la pasul curent\n",
    "            current_step_sum = NaN;\n",
    "\n",
    "            % TODO 3: Calculează suma care folosește valori calculate la pasul anterior\n",
    "            last_step_sum = NaN;\n",
    "\n",
    "            % TODO 4: Calculează noua valoare a elementului x(i)\n",
    "        endfor\n",
    "\n",
    "        % TODO 5: Verifică daca s-a ajuns la o soluție suficient de bună\n",
    "        % Hint: funcția norm\n",
    "        \n",
    "        % TODO 6: Actualizează soluția precedentă cu cea curentă\n",
    "        x_last_step = x_current_step;\n",
    "    endfor\n",
    "endfunction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda Suprarelaxării\n",
    "\n",
    "După cum s-a observat din metodele iterative prezentate anterior rata de convergență depinde de raza spectrală a matricei\n",
    "asociate. **Metoda suprarelaxării** (**SOR- Successive Over-Relaxation**) își propune să accelereze convergența prin alegerea unei\n",
    "matrice asociate cu raza spectrală minimă. Astfel, pentru găsirea unei metode cât mai rapid convergente se alege un\n",
    "parametru de relaxare $\\omega$:\n",
    "\n",
    "Pornind de la $A = N - P = N - \\omega N - P + \\omega N = (1 - \\omega) N - (P - \\omega N) = N_\\omega - P_\\omega $\n",
    "\n",
    "**Totuși, cum alegem $\\omega$** ? Problema acestei metode rămâne selectarea unui $\\omega$ optim astfel încât metoda sa conveargă cât mai rapid. Deoarece nu există criterii de selectare pentru $\\omega$ optim metoda nu se aplică punctual. Aceasta este folosită în situația în care pentru aceeași matrice a coeficienților, A, trebuie calculate mai multe soluții pentru diferiți vectori de termeni liberi. Astfel, pentru un eșantion din sistemele ce trebuie rezolvate se testează convergența metodei folosind diferite valori ale lui $\\omega$ , pentru ca mai apoi, pe restul sistemelor sa fie folosită valoarea optimă din cele testate anterior.\n",
    "\n",
    "\n",
    "### Formulele de la SOR\n",
    "Vom alege următoarele matrice:\n",
    "\n",
    "\\$N_\\omega = (1-\\omega)N  \\$ <br>\n",
    "\\$P_\\omega = P-\\omega N\\$ <br>\n",
    "\\$G_\\omega\\$ = \\$N_\\omega^{-1} P_\\omega\\$ <br>\n",
    "\n",
    "Însă în practică se face o altă alegere, astfel:\n",
    "\n",
    "\\$N_\\omega = (1/\\omega )D-L \\$ <br>\n",
    "\\$P_\\omega = (1/\\omega-1)D + U \\$ <br>\n",
    "\\$G_\\omega = (D-\\omega L)^{-1}  [ (1-\\omega)D+\\omega U] \\$ <br>\n",
    "\n",
    "Soluția sistemului se poate scrie recurent sub forma:\n",
    "$$x_i^{(p+1)} = \\displaystyle\\omega \\frac{b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(p+1)} - \n",
    "\\sum_{j=i+1}^{n} a_{ij} x_j^{(p)}\n",
    "}{a_{ii}}+(1-\\omega)x_i^{(p)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observații\n",
    "\n",
    "1. Metoda converge doar dacă $ \\omega \\in (0,2) $;\n",
    "\n",
    "2. Pentru $0 < \\omega < 1$,  metoda se numește subrelaxare;\n",
    "\n",
    "3. Pentru $1 < \\omega $,  metoda se numeste suprarelaxare;\n",
    "\n",
    "4. Pentru $\\omega = 1$, SOR este echivalent cu Gauss-Seidel;\n",
    "\n",
    "5. A - pozitiv definită este condiție necesară, dar nu sufucientă;\n",
    "\n",
    "6. Dacă A este o matrice pozitiv definită și $0 < \\omega\\ < 2$, atunci metoda SOR converge\n",
    "pentru orice alegere a aproximației inițiale $ x^{(0)} $;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% !!! Exercițiu punctat !!!\n",
    "\n",
    "function [success] = ConvergesSOR(A, b, x0, tol, max_iter, w)\n",
    "    % Completați următoarele linii pentru a stabili daca matricea A converge pentru metoda SOR\n",
    "    N = NaN;\n",
    "    P = NaN;\n",
    "    G = NaN;\n",
    "    % Calculați raza spectrală a matricei G\n",
    "    spectral_radius = NaN;\n",
    "    success = NaN;\n",
    "endfunction\n",
    "\n",
    "% Testați implementarea\n",
    "[success] = ConvergesSOR([4 1 2 0; 3 -2 0 -1; -1 3 5 1; 2 1 0 5], [5; -4; 1], [0; 0; 0], 0.01, 20, 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[passed, total] = test (\"ConvergesSOR.test\", \"verbose\");\n",
    "disp(strcat('Punctaj:', mat2str(passed), '/', mat2str(total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Testati codul urmator pentru mai multe valori ale lui w. Ce observati?\n",
    "function [x_current_step step] = SOR(A, b, x0, tol, max_iter, w)\n",
    "    n = length(b);\n",
    "    x_last_step = x0;\n",
    "    x_current_step = x0;\n",
    "    %TODO 1: Verifică dacă valoarea lui w aparține intervalului (0, 2)\n",
    "    \n",
    "    %TODO 2: Verifică dacă matricea A converge\n",
    "    \n",
    "    % Iterează până la numărul maxim de pași acceptat\n",
    "    for step = 1 : max_iter\n",
    "        % Itereaza prin fiecare x(i)\n",
    "        for i = 1 : n\n",
    "            %TODO 3: Suma valorilor aflate la iterația curentă\n",
    "            new_values_sum = 0; \n",
    "            \n",
    "            %TODO 4: Suma valorilor aflate la iteratia anterioară\n",
    "            old_values_sum = 0;\n",
    "            \n",
    "            x(i) = (b(i) - (old_values_sum + new_values_sum))/A(i,i);\n",
    "            % TODO 5: Calcularea lui x(i) folosind parametrul de relaxare\n",
    "            x(i) = 0;\n",
    "        endfor\n",
    "        \n",
    "        % TODO 6: Verifică daca s-a ajuns la o soluție suficient de bună\n",
    "        % Hint: funcția norm\n",
    "        \n",
    "        % TODO 7: Actualizează soluția precedentă cu cea curentă\n",
    "        x_last_step = x_current_step;\n",
    "    endfor\n",
    "\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probleme rezolvate\n",
    "\n",
    "### Problema 1 (Wassily Leontief won the Nobel prize in economics in 1973)\n",
    "\n",
    "O economie este formată din trei industrii: alimentară (A), chimică(C) și cea de prelucrare a lemnului(L). Consumul curent este dat de următorul tabel(unitățile fiind de ordinul miilor): <br>\n",
    "\n",
    "| Productie   | A | C  | L | Extern |\n",
    "| ----------- | - | -- | - | ------ |\n",
    "| Industria A | 3 | -1 | 1 | 1      | \n",
    "| Industria C | 3 | 6  | 2 | 0      |\n",
    "| Industria L | 3 | 3  | 7 | 4      |\n",
    "\n",
    "Având în vedere datele precizate determinați nivelele de producție ulterioare.\n",
    "\n",
    "Soluție:\n",
    "\n",
    "\\begin{cases} 3x_{1} - x_{2} + x_{3} = 1 \\\\ 3x_{1} + 6x_{2} + 2x_{3} = 0 \\\\ 3x_{1} + 3x_{2} + 7x_{3} = 4 \\end{cases}\n",
    "\n",
    "Alegem aproximația inițială $x^{(0)}$ = (0,0,0)';\n",
    "\n",
    "Pasul 1: Scriem formula de recurență:\n",
    "\n",
    "\\begin{cases} x_{1}^{(k+1)} = \\frac13[x_{2}^{(k)} - x_{3}^{(k)} + 1] \\\\ x_{2}^{(k+1)} = \\frac16[- 3x_{1}^{(k)} - 2x_{3}^{(k)}] \\\\ x_{3}^{(k+1)} = \\frac17 [-3x_{1}^{(k)} -3x_{2}^{(k)} + 4] \\end{cases}\n",
    "\n",
    "Pasul 2: Determinăm prima aproximație a soluției $x_{1}^{(1)}$ $x_{2}^{(1)}$ $x_{3}^{(1)}$ cu ajutorul aproximației ințiale $x^{(0)}$=(0,0,0)'.\n",
    "\n",
    "\\begin{cases} x_{1}^{(1)} = \\frac13[x_{2}^{(0)} - x_{3}^{(0)} + 1] \\approx 0.3333 \\\\ x_{2}^{(1)} = \\frac16[- 3x_{1}^{(0)} - 2x_{3}^{(0)}] = 0 \\\\ x_{3}^{(1)} = \\frac17 [-3x_{1}^{(0)} -3x_{2}^{(0)} + 4] \\approx 0.5714 \\end{cases}\n",
    "\n",
    "Pasul 3: Determinăm a doua aproximație a soluției $x_{1}^{(2)}$ $x_{2}^{(2)}$ $x_{3}^{(2)}$ cu ajutorul aproximației obținute după prima iterație $x^{(1)}$=(0.3333,0,0.5714)'.\n",
    "\n",
    "\\begin{cases} x_{1}^{(2)} = \\frac13[x_{2}^{(1)} - x_{3}^{(1)} + 1] \\approx 0.1428 \\\\ x_{2)}^{(2)} = \\frac16[- 3x_{1}^{(1)} - 2x_{3}^{(1)}] \\approx 0.3571 \\\\ x_{3}^{(2} = \\frac17 [-3x_{1}^{(1)} -3x_{2}^{(1)} + 4] \\approx 0.4285 \\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2\n",
    "\n",
    "Confecționarea unui dispozitiv semiconductor integrat necesită sute de pași de producție care pot fi clasificați în două mari categorii: pași care definesc structura și pași care influențează distribuția dopanților. Simulări numerice au scopul de a controla acești pași, de a optimiza procesul si de a accelera producția. Modelele trebuie construite, ajustate si evaluate matematic, astfel obținându-se sisteme de dimensiuni mari ce trebuie rezolvate.\n",
    "\n",
    "Pentru o variantă simplificată a unui astfel de sistem, aflați necunoscutele folosind metoda Gauss-Seidel.\n",
    "\n",
    "\\begin{cases} 3x_{1} - x_{2} + x_{3} = 1 \\\\ 3x_{1} + 6x_{2} + 2x_{3} = 0 \\\\ 3x_{1} + 3x_{2} + 7x_{3} = 4 \\end{cases}\n",
    "\n",
    "Alegem aproximația inițială $x^{(0)}$ = (0,0,0)';\n",
    "\n",
    "Soluție:\n",
    "\n",
    "Pasul 1: Scriem formula de recurență:\n",
    "\n",
    "\\begin{cases} x_{1}^{(k+1)} = \\frac13[x_{2}^{(k)} - x_{3}^{(k)} + 1] \\\\ x_{2}^{(k+1)} = \\frac16[- 3x_{1}^{(k+1)} - 2x_{3}^{(k)}] \\\\ x_{3}^{(k+1)} = \\frac17 [-3x_{1}^{(k+1)} -3x_{2}^{(k+1)} + 4] \\end{cases}\n",
    "\n",
    "\n",
    "Pasul 2: Determinăm prima aproximație a soluției $x_{1}^{(1)}$ $x_{2}^{(1)}$ $x_{3}^{(1)}$ cu ajutorul aproximației ințiale $x^{(0)}$=(0,0,0)'.\n",
    "\n",
    "\\begin{cases} x_{1}^{(1)} = \\frac13[x_{2}^{(0)} - x_{3}^{(0)} + 1] \\approx 0.3333 \\\\ x_{2}^{(1)} = \\frac16[- 3x_{1}^{(1)} - 2x_{3}^{(0)}] \\approx -0.1666 \\\\ x_{3}^{(1)} = \\frac17 [-3x_{1}^{(0)} -3x_{2}^{(0)} + 4] \\approx 0.5000 \\end{cases}\n",
    "\n",
    "Pasul 3: Determinăm a doua aproximație a soluției $x_{1}^{(2)}$ $x_{2}^{(2)}$ $x_{3}^{(2)}$ cu ajutorul aproximației obținute după prima iterație $x^{(1)}$=(0.3333,-0.1666,0.5000)'.\n",
    "\n",
    "\\begin{cases} x_{1}^{(2)} = \\frac13[x_{2}^{(1)} - x_{3}^{(1)} + 1] \\approx 0.1111 \\\\ x_{2)}^{(2)} = \\frac16[- 3x_{1}^{(2)} - 2x_{3}^{(1)}] \\approx -0.2222 \\\\ x_{3}^{(2)} = \\frac17 [-3x_{1}^{(2)} -3x_{2}^{(2)} + 4] \\approx 0.6190 \\end{cases}\n",
    "\n",
    "| k | $x_{1}^{(k)}$ | $x_{2}^{(k)}$ | $x_{3}^{(k)}$ |\n",
    "| --- | --- | --- | --- |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 1 | 0.3333 | -0.1667 | 0.5000 |\n",
    "| 2 | 0.1111 | -0.2222 | 0.6190 |\n",
    "| 3 | 0.0529 | -0.2328 | 0.6485 |\n",
    "| 4 | 0.0396 | -0.2360 | 0.6556 |\n",
    "| 5 | 0.0361 | -0.2366 | 0.6573 |\n",
    "| 6 | 0.0354 | -0.2368 | 0.6578 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3\n",
    "\n",
    "Fie sistemul $Ax = b, A \\in R^{2x2}; x, b \\in R^{2}$\n",
    "\n",
    "$A = \\begin{bmatrix}2 & 2\\\\ 1 & 3\\end{bmatrix}$. Matricea A nu este diagonal dominantă pe linii. În ce condiții este convergentă metoda Gauss-Seidel?\n",
    "\n",
    "Soluție:\n",
    "\n",
    "Se determină matricea de iterație a sistemului pentru metoda Gauss-Seidel, $G_{GS}$. $A = D-L-U$, deci \n",
    "$D = \\begin{bmatrix} 2 & 0 \\\\ 0 & 3 \\end{bmatrix}, L = \\begin{bmatrix} 0 & 0 \\\\ -1 & 0 \\end{bmatrix}, U = \\begin{bmatrix} 0 & -2 \\\\ 0 & 0 \\end{bmatrix}$\n",
    "\n",
    "Atunci:\n",
    "\n",
    "$G_{GS} = (D-L)^{-1}U = \\begin{bmatrix} 2 & 0 \\\\ 1 & 3 \\end{bmatrix}^{-1}\\begin{bmatrix} 0 & -2 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & -1 \\\\ 0 & 1/3 \\end{bmatrix}.$ \n",
    "\n",
    "$det(\\lambda I-G_{GS})$ = $\\begin{vmatrix} \\lambda & 1 \\\\ 0 & \\lambda -1/3 \\end{vmatrix} = 0,$ deci $\\lambda (G_{GS})$ = {0,1/3} și $\\rho  (G_{GS}) = 1/3 < 1$ $\\Rightarrow$ metoda Gauss-Seidel este convergentă."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propleme propuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1\n",
    "Determinați pentru care dintre următoarele matrice, metoda Gauss-Seidel converge:<br>\n",
    "a) $\\begin{bmatrix}\n",
    "    2 & -1 \\\\\n",
    "    -1 & 2\n",
    "   \\end{bmatrix}$\n",
    "b) $\\begin{bmatrix}\n",
    "    2 & 1 & 1 \\\\\n",
    "    1 & 2 & 1 \\\\\n",
    "    1 & 1 & 2\n",
    "\\end{bmatrix}$\n",
    "c) $\\begin{bmatrix}\n",
    "1/2 & 0 & 0 \\\\\n",
    "2 & 1/2 & 0 \\\\\n",
    "3 & 4 & 1/2\n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Modificați exercițiul anterior folosind următorul antet\n",
    "function [x_current_step step] = GaussSeidel_Tri(d1, d2, d3, b, x0, tol, max_iter)\n",
    "% d1, d2, d3 diagonalele matricei\n",
    "\n",
    "    x_current_step = x0\n",
    "endfunction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
